# üîß Soluci√≥n: Errores de OpenAI cuando se carga el proyecto

## Problema

Cuando se carga un proyecto, la app muestra errores como "sin cr√©dito" o "rate limit", pero **S√ç hay cr√©dito** y la IA funciona cuando **NO** se carga el proyecto.

## Causa Ra√≠z

El problema es que cuando se carga el proyecto, se env√≠a **demasiado contexto** a la API de OpenAI:

- **Antes:** Hasta 20 archivos √ó 50KB = **1MB de contexto** por solicitud
- Esto puede causar:
  - ‚ùå Errores de `context_length_exceeded` (mensaje demasiado largo)
  - ‚ùå Errores de rate limit por tama√±o de solicitud
  - ‚ùå Errores que se interpretan incorrectamente como "sin cr√©dito"

## Soluci√≥n Implementada

### 1. Reducci√≥n del Contexto

**Archivo:** `lib/services/project_context_service.dart`

```dart
// ANTES:
int maxFiles = 20;
int maxFileSize = 50000; // 50KB

// AHORA:
int maxFiles = 5;        // Solo 5 archivos principales
int maxFileSize = 10000; // Solo 10KB por archivo
```

Esto reduce el contexto de **1MB a ~50KB m√°ximo**.

### 2. Manejo de Errores Espec√≠ficos

**Archivo:** `lib/services/openai_service.dart`

- ‚úÖ Agregado manejo de `context_length_exceeded` (error 400)
- ‚úÖ Mejorado el parsing de errores para distinguir entre:
  - `insufficient_quota` (sin cr√©dito real)
  - `rate_limit` (demasiadas solicitudes)
  - `context_length_exceeded` (mensaje muy largo)
  - `invalid_api_key` (clave inv√°lida)

### 3. Logging y Truncamiento

**Archivo:** `lib/screens/chat_screen.dart`

- ‚úÖ Agregado logging del tama√±o del contexto
- ‚úÖ Truncamiento autom√°tico si el contexto excede 50KB
- ‚úÖ Manejo de errores al obtener el contexto (contin√∫a sin contexto si falla)

## Verificaci√≥n

Para verificar que funciona:

1. **Carga un proyecto peque√±o primero** para probar
2. **Revisa los logs** en la consola de Flutter:
   ```
   üìä Tama√±o del contexto del proyecto: X caracteres
   üìä Tama√±o del resumen: Y caracteres
   ```

3. **Si el contexto es muy grande**, se truncar√° autom√°ticamente:
   ```
   ‚ö†Ô∏è Contexto muy grande (X chars), reduciendo...
   ```

## Pr√≥ximos Pasos (Opcional)

Si a√∫n tienes problemas con proyectos muy grandes, puedes:

1. **Reducir m√°s el contexto:**
   - Cambiar `maxFiles` de 5 a 3
   - Cambiar `maxFileSize` de 10000 a 5000

2. **Hacer el contexto opcional:**
   - Solo enviar contexto cuando el usuario lo pida expl√≠citamente
   - O enviar solo la estructura, no el contenido de archivos

3. **Usar archivos espec√≠ficos:**
   - Solo enviar archivos relevantes seg√∫n el mensaje del usuario
   - No enviar todo el proyecto siempre

## Notas Importantes

- **Los l√≠mites de tokens de OpenAI:**
  - `gpt-4o`: ~128,000 tokens de contexto
  - `gpt-4-turbo`: ~128,000 tokens de contexto
  - `gpt-3.5-turbo`: ~16,385 tokens de contexto

- **1 token ‚âà 4 caracteres** (en promedio)
- **50KB de contexto ‚âà 12,500 tokens** (dentro del l√≠mite)

- **Si el proyecto es muy grande**, considera:
  - Usar archivos espec√≠ficos en lugar del proyecto completo
  - Implementar un sistema de "lazy loading" del contexto
  - Usar res√∫menes de archivos en lugar del contenido completo

